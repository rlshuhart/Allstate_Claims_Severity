{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import matplotlib as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import training data set\n",
    "train = pd.read_csv(\"../data/raw/train.csv.zip\", compression=\"zip\", index_col='id')\n",
    "meta_data = pd.read_csv(\"../data/interim/training_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Names\n",
    "cat_names = meta_data[meta_data['Data Type']=='object']['Variable']\n",
    "cont_names = meta_data[(meta_data['Data Type']=='float64') & \n",
    "                       (meta_data['Variable']!='loss')]['Variable']\n",
    "\n",
    "# Merge transformed categorical data with continuous\n",
    "cont_names_to_drop =['cont12' # highly correlated to cont11\n",
    "                     ,'cont9' # highly correlated to cont1\n",
    "                    ]\n",
    "cont_names_final = cont_names[~cont_names.isin(cont_names_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryan.shuhart\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\category_encoders\\ordinal.py:190: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[col] = X[col].astype(int).reshape(-1, )\n",
      "C:\\Users\\ryan.shuhart\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\category_encoders\\ordinal.py:179: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  X[switch.get('col')] = X[switch.get('col')].astype(int).reshape(-1, )\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "encoder = ce.BinaryEncoder()\n",
    "\n",
    "categorical_data = encoder.fit_transform(train[cat_names])\n",
    "continuous_data = train[cont_names]\n",
    "\n",
    "train_final1 = pd.concat([train[cont_names], categorical_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_final1 = pd.concat([train[cont_names], categorical_data], axis=1)\n",
    "X=train_final1.values\n",
    "y=train['loss'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1328.66 (+/- 62.59)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "scorer = make_scorer(mean_absolute_error)\n",
    "clf = linear_model.SGDRegressor()\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring=scorer)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F-Score:  1893.1984383073209\n",
      "Best Parameters:  {'penalty': 'l2', 'loss': 'huber'}\n",
      "Best Estimator:  SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.01,\n",
      "       fit_intercept=True, l1_ratio=0.15, learning_rate='invscaling',\n",
      "       loss='huber', n_iter=5, penalty='l2', power_t=0.25,\n",
      "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'loss':['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "               'penalty':['none', 'l2', 'l1', 'elasticnet']\n",
    "              }]\n",
    "\n",
    "gs = GridSearchCV(estimator=clf, param_grid=param_grid, cv=3, n_jobs=-1, scoring=scorer)\n",
    "gs = gs.fit(X, y)\n",
    "\n",
    "print(\"Best F-Score: \", gs.best_score_)\n",
    "print(\"Best Parameters: \", gs.best_params_)\n",
    "print(\"Best Estimator: \", gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:   2%|‚ñè         | 2/120 [05:19<3:24:22, 103.92s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GP closed prematurely - will use current best pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "ValueError: A pipeline has not yet been optimized. Please call fit() first.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A pipeline has not yet been optimized. Please call fit() first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.6, test_size=0.4)\n",
    "\n",
    "tpot = TPOTRegressor(generations=5, population_size=20, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('../models/tpot_pipeline.py')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
